{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "QfzRALX0dYED",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18f73ee9-6c1c-47ee-b624-c3bf8f99e45e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded dataset: (489, 3) (489, 1)\n",
            "Running: hidden=3, lr=0.01, k=5\n",
            " -> mean MSE (scaled target) = 0.024886, std = 0.011573\\n\n",
            "Running: hidden=3, lr=0.01, k=10\n",
            " -> mean MSE (scaled target) = 0.035471, std = 0.014229\\n\n",
            "Running: hidden=4, lr=0.001, k=5\n",
            " -> mean MSE (scaled target) = 0.036220, std = 0.018449\\n\n",
            "Running: hidden=4, lr=0.001, k=10\n",
            " -> mean MSE (scaled target) = 0.029660, std = 0.009780\\n\n",
            "Running: hidden=5, lr=0.0001, k=5\n",
            " -> mean MSE (scaled target) = 0.330732, std = 0.508923\\n\n",
            "Running: hidden=5, lr=0.0001, k=10\n",
            " -> mean MSE (scaled target) = 0.241056, std = 0.195116\\n\n"
          ]
        }
      ],
      "source": [
        "# Imports and data load (use the provided housing CSV)\n",
        "import numpy as np, pandas as pd, os, math, random\n",
        "np.random.seed(42)\n",
        "df = pd.read_csv('/content/housing (1).csv')\n",
        "X_full = df.drop(columns=['MEDV']).to_numpy(dtype=float)\n",
        "y_full = df['MEDV'].to_numpy(dtype=float).reshape(-1,1)\n",
        "print(\"Loaded dataset:\", X_full.shape, y_full.shape)\n",
        "\n",
        "\n",
        "# Define NN class (NumPy-only)\n",
        "class NN:\n",
        "    def __init__(self, input_size, hidden_size, output_size=1, lr=0.01):\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.lr = lr\n",
        "        limit1 = np.sqrt(6 / (input_size + hidden_size))\n",
        "        limit2 = np.sqrt(6 / (hidden_size + output_size))\n",
        "        self.W1 = np.random.uniform(-limit1, limit1, (input_size, hidden_size))\n",
        "        self.b1 = np.zeros((1, hidden_size))\n",
        "        self.W2 = np.random.uniform(-limit2, limit2, (hidden_size, output_size))\n",
        "        self.b2 = np.zeros((1, output_size))\n",
        "    def sigmoid(self, x):\n",
        "        return 1.0 / (1.0 + np.exp(-x))\n",
        "    def sigmoid_deriv(self, s):\n",
        "        return s * (1 - s)\n",
        "    def forward(self, X):\n",
        "        z1 = np.dot(X, self.W1) + self.b1\n",
        "        a1 = self.sigmoid(z1)\n",
        "        z2 = np.dot(a1, self.W2) + self.b2\n",
        "        yhat = z2\n",
        "        cache = {'X': X, 'z1': z1, 'a1': a1, 'z2': z2}\n",
        "        return yhat, cache\n",
        "    def compute_loss(self, yhat, y):\n",
        "        return np.mean((yhat - y) ** 2)\n",
        "    def backward(self, cache, yhat, y):\n",
        "        n = y.shape[0]\n",
        "        a1 = cache['a1']\n",
        "        X = cache['X']\n",
        "        dz2 = (2.0 * (yhat - y)) / n\n",
        "        dW2 = np.dot(a1.T, dz2)\n",
        "        db2 = np.sum(dz2, axis=0, keepdims=True)\n",
        "        da1 = np.dot(dz2, self.W2.T)\n",
        "        dz1 = da1 * self.sigmoid_deriv(a1)\n",
        "        dW1 = np.dot(X.T, dz1)\n",
        "        db1 = np.sum(dz1, axis=0, keepdims=True)\n",
        "        self.W2 -= self.lr * dW2\n",
        "        self.b2 -= self.lr * db2\n",
        "        self.W1 -= self.lr * dW1\n",
        "        self.b1 -= self.lr * db1\n",
        "    def fit(self, X, y, epochs=1000, verbose=False):\n",
        "        history = {'loss': []}\n",
        "        for ep in range(epochs):\n",
        "            yhat, cache = self.forward(X)\n",
        "            loss = self.compute_loss(yhat, y)\n",
        "            history['loss'].append(loss)\n",
        "            self.backward(cache, yhat, y)\n",
        "            if verbose and (ep % 100 == 0 or ep==epochs-1):\n",
        "                print(f\"Epoch {ep+1}/{epochs}  loss={loss:.6f}\")\n",
        "        return history\n",
        "    def predict(self, X):\n",
        "        yhat, _ = self.forward(X)\n",
        "        return yhat\n",
        "\n",
        "\n",
        "# K-fold split and scaling helpers (min-max using training fold)\n",
        "def k_fold_split(X, y, k=5, seed=42):\n",
        "    n = X.shape[0]\n",
        "    idx = np.arange(n)\n",
        "    rng = np.random.RandomState(seed)\n",
        "    rng.shuffle(idx)\n",
        "    folds = []\n",
        "    fold_sizes = [(n // k) + (1 if i < (n % k) else 0) for i in range(k)]\n",
        "    current = 0\n",
        "    for fs in fold_sizes:\n",
        "        test_idx = idx[current: current+fs]\n",
        "        train_idx = np.setdiff1d(idx, test_idx)\n",
        "        folds.append((train_idx, test_idx))\n",
        "        current += fs\n",
        "    return folds\n",
        "def fit_scaler(X):\n",
        "    min_ = X.min(axis=0, keepdims=True)\n",
        "    max_ = X.max(axis=0, keepdims=True)\n",
        "    range_ = np.where(max_ - min_ == 0, 1.0, max_ - min_)\n",
        "    return {'min': min_, 'range': range_}\n",
        "def transform_scaler(X, scaler):\n",
        "    return (X - scaler['min']) / scaler['range']\n",
        "\n",
        "\n",
        "# Run CV experiment function (this will be used below)\n",
        "def run_cv_experiment(X_full, y_full, hidden_neurons, lr, k=5, epochs=1000, seed=42):\n",
        "    folds = k_fold_split(X_full, y_full, k=k, seed=seed)\n",
        "    val_losses = []\n",
        "    for i, (train_idx, test_idx) in enumerate(folds):\n",
        "        X_train, y_train = X_full[train_idx], y_full[train_idx]\n",
        "        X_test, y_test = X_full[test_idx], y_full[test_idx]\n",
        "        X_scaler = fit_scaler(X_train)\n",
        "        y_scaler = fit_scaler(y_train)\n",
        "        X_train_s = transform_scaler(X_train, X_scaler)\n",
        "        X_test_s = transform_scaler(X_test, X_scaler)\n",
        "        y_train_s = transform_scaler(y_train, y_scaler)\n",
        "        y_test_s = transform_scaler(y_test, y_scaler)\n",
        "        model = NN(input_size=X_train_s.shape[1], hidden_size=hidden_neurons, output_size=1, lr=lr)\n",
        "        model.fit(X_train_s, y_train_s, epochs=epochs, verbose=False)\n",
        "        ypred = model.predict(X_test_s)\n",
        "        loss = model.compute_loss(ypred, y_test_s)\n",
        "        val_losses.append(loss)\n",
        "    val_losses = np.array(val_losses)\n",
        "    return {'mean_mse': float(val_losses.mean()), 'std_mse': float(val_losses.std()), 'fold_losses': val_losses.tolist()}\n",
        "\n",
        "\n",
        "# Run the three settings for 5-fold and 10-fold CV (1000 epochs)\n",
        "settings = [\n",
        "    {'hidden':3, 'lr':0.01},\n",
        "    {'hidden':4, 'lr':0.001},\n",
        "    {'hidden':5, 'lr':0.0001},\n",
        "]\n",
        "results = {}\n",
        "for s in settings:\n",
        "    for k in [5,10]:\n",
        "        print(f\"Running: hidden={s['hidden']}, lr={s['lr']}, k={k}\")\n",
        "        res = run_cv_experiment(X_full, y_full, hidden_neurons=s['hidden'], lr=s['lr'], k=k, epochs=1000)\n",
        "        print(f\" -> mean MSE (scaled target) = {res['mean_mse']:.6f}, std = {res['std_mse']:.6f}\\\\n\")\n",
        "        results[(s['hidden'], s['lr'], k)] = res\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "BfK3kKHbfAaU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}